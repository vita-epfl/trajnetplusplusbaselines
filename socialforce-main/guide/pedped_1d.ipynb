{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import socialforce\n",
    "\n",
    "_ = torch.manual_seed(43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(pedped-1d)=\n",
    "# 1D\n",
    "\n",
    "## Parametric\n",
    "\n",
    "We start with the simple case where the potential $V(b)$ is approximated only \n",
    "by the classical Social Force potential SF:\n",
    "\\begin{align}\n",
    "    V(b) &= \\textrm{SF}(b) \\\\\n",
    "    \\textrm{SF}(b) &= V_0 \\exp(-b / \\sigma)\n",
    "\\end{align}\n",
    "with its two parameters $V_0$ and $\\sigma$. Although it is a single-argument\n",
    "function, the argument $b$ is the semi-minor axis of an ellipse, a 2D object:\n",
    "\\begin{align}\n",
    "    2b &= \\sqrt{||\\vec{r}_{\\alpha\\beta}|| + ||\\vec{r}_{\\alpha\\beta} - v_{\\beta}\\Delta t \\vec{e}_{\\beta}|| - (v_{\\beta}\\Delta t)^2}\n",
    "\\end{align}\n",
    "as defined in {cite}`helbing1995social` with $\\vec{r}_{\\alpha\\beta} = \\vec{r}_{\\alpha} - \\vec{r}_{\\beta}$. \n",
    "We can compare this with $2b = \\sqrt{(p + q)^2 - d^2}$ where the\n",
    "three parameters are the distance to the first focal point $p$,\n",
    "the distance to the second focal point $q$ and the distance between the \n",
    "focal points $d$.\n",
    " \n",
    "We can visualize this potential in terms of its value and the magnitude\n",
    "of its gradients in the physical coordinates of a pedestrian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = socialforce.potentials.PedPedPotential()\n",
    "with socialforce.show.canvas(figsize=(12, 6), ncols=2) as (ax1, ax2):\n",
    "    socialforce.show.potential_2d(V, ax1)\n",
    "    socialforce.show.potential_2d_grad(V, ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pedestrian is located in the left focal point of the ellipse and at their \n",
    "current speed can reach the right focal point within one step that is assumed\n",
    "to take $\\Delta t = 0.4s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Scenario\n",
    "\n",
    "We generate a single {ref}`Circle scenario <scenarios>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circle = socialforce.scenarios.Circle()\n",
    "scenarios = circle.generate(1)\n",
    "true_experience = socialforce.Trainer.scenes_to_experience(scenarios)\n",
    "\n",
    "with socialforce.show.track_canvas() as ax:\n",
    "    socialforce.show.states(ax, scenarios[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "We infer the parameters of an MLP to approximate the 1D scalar \n",
    "function $\\textrm{SF}(b)$ above from synthetic observations.\n",
    "The `PedPedPotentialMLP` is a two-layer MLP with softplus activations:\n",
    "\\begin{align}\n",
    "    \\textrm{MLP}(b) &= \\textrm{Softplus} \\;\\; L_{1\\times5} \\;\\; \\textrm{Softplus} \\;\\; L_{5\\times1} \\;\\; b\n",
    "\\end{align}\n",
    "which is written in terms of linear and non-linear operators where\n",
    "the Softplus operator applies the softplus function on its input from the right\n",
    "and $L$ is a linear operator (a matrix) with the subscript indicating the \n",
    "$\\textrm{output features} \\times \\textrm{input features}$.\n",
    "This two-layer MLP with 5 hidden units has 10 parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = socialforce.potentials.PedPedPotentialMLP()\n",
    "initial_state_dict = copy.deepcopy(V.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "We use a standard optimizer from PyTorch (SGD).\n",
    "You can specify a standard PyTorch loss function for the `Trainer` as well\n",
    "but here the default of a `torch.nn.L1Loss()` is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE OUTPUT\n",
    "simulator = socialforce.Simulator(ped_ped=V) \n",
    "opt = torch.optim.SGD(V.parameters(), lr=1.0)\n",
    "socialforce.Trainer(simulator, opt).loop(100, true_experience, log_interval=10)\n",
    "final_state_dict = copy.deepcopy(V.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "with socialforce.show.canvas(ncols=2, figsize=(10, 4)) as (ax1, ax2):\n",
    "    socialforce.show.potential_1d_parametric(\n",
    "        circle.ped_ped, ax1, ax2, \n",
    "        label=r'true $V_0 e^{-b/\\sigma}$', sigma_label=r'true $\\sigma$', color='gray')\n",
    "\n",
    "    V.load_state_dict(initial_state_dict)\n",
    "    socialforce.show.potential_1d(V, ax1, ax2, label=r'initial MLP($b$)', linestyle='dashed', color='C0')\n",
    "\n",
    "    V.load_state_dict(final_state_dict)\n",
    "    socialforce.show.potential_1d(V, ax1, ax2, label=r'MLP($b$)', color='C0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generated a single synthetic scene with two pedestrians with a parametric\n",
    "potential that was the standard Social Force potential. \n",
    "That parametric potential is shown in gray in the above plot.\n",
    "Then we trained an MLP\n",
    "to infer its parameters. In the above plot, you see the MLP with its initialized\n",
    "random parameters as a dashed line and with its inferred parameters as a solid \n",
    "line. During the training process, the function values of the generating potential\n",
    "were never accessed. Only observed simulation steps were used to train the potential."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "interpreter": {
   "hash": "29864609ce42acb949f1cb2f5c54bbb80a5cac9b20d76f096c9b799bd2af5ed7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv3': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "29864609ce42acb949f1cb2f5c54bbb80a5cac9b20d76f096c9b799bd2af5ed7"
   }
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
